---
title:  "시멘틱웹"
excerpt: "텐서플로우"

categories:
  - New
tags:
  - [New, Github]

toc: true
toc_sticky: true
 
date: 2023-06-15
last_modified_at: 2023-06-15
---

# 머신러닝의 기초 개념 (optimizer, loss function, activation function 등)

- 머신러닝이란?
    - 인공지능의 하위분야이면, 딥러닝이 "인공신경망"을 이용해 학습한다면, 머신러닝은 "알고리즘"으로부터 데이터를 학습한다. 

- 최적화 알고리즘 
    - 네트워크가 데이터와 손실함수를 기반으로 최적의 가중치를 업데이트한다. 
    - 종류 
        - sgd
        - adam
        - adamax
        - adadelta
        - momentum 
    - 목적 및 사용이유
        - 과적합을 방지해 모델의 일반화 성능을 향상시킨다. 
        - 국소최적화를 방지한다. 
        - 최적의 가중치를 찾기 위함

- 손실 함수 
    - 모델의 예측값과 실제값 간의 차이 측정 
    - 종류 
        - mse 
        - mae 
        - 이진분류 -> Binarycrossentropy   - 두 클래스 구분
        - 다중분류 -> Categoricalcrossentropy - 확률분포비교
    - 목적 및 사용이유
        - 최적화 알고리즘이 최적의 가중치를 업데이트 하기 위해 필요
        - 모델의 성능 평가 

- 활성화 함수 
    - 입력신호의 총합을 출력 신호로 변환 
    - 종류 
        - sigmoid 
        - softmax
        - relu
        - tanH 
    - 목적 및 사용이유 
        - 선형함수만을 이용하면 표현력이 제한되기 때문에 
        - 출력 값 결정 

- 그 외 기초 개념 
    - 훈련, 테스트, 검증 데이터 
    - 지도/비지도 학습 
    - 재현율(recall)/정밀도(precisiin)/정확도(accuracy) -> 모델의 평가지표 
    - 과소적합/과대적합 

# 합성곱 신경망의 개념, 일반적인 구조와 동작방식 이해(컨볼루션, 풀링 등)

- 합성곱 신경망 
    - CNN(Convolutional Neural Network) -> 이미지, 비디오 및 음성과 같은 시각, 청각 신호를 분석하는 딥러닝의 한분야이다. cnn은 입렵데이터의 지역 패턴을 인식하고, 그 패턴을 조합해 다양한 특성을 추출할 수 있다. 
1. 컨봍루션 층 
    - 필터(커널)를 이용해 입력이미지의 겹치는 부분과 각 픽셀값을 곱하고 더한 후 출력 이미지의 픽셀 값으로 사용한다. 
    - 일반적으로 비선형 활성화 함수를 사용한다. 
    - 국소성 - 작은 커널 윈도 안에 있는 지역 패턴 학습 가능
    - 파라미터 공유 - 동일한 커널을 사용해 이를 바탕으로 모델의 일반화 성능 향상 

2. 풀링 층 
    - 풀링은 출력에 대한 '요약' 제공 
    - 필터(커널)의 크기를 줄여 입력데이터에 대한 전체적인 속도를 향상시킨다.
    - maxpooling을 주로 사용한다. 
        - maxpooling은 작은 이미지 패치 내에서 가장 큰 픽셀 값을 출력 이미지의 픽셀 값으로 사용한다. 
    - 학습하지 않는다. 단지 컨볼루션 층에서 온 이미지를 다운샘플링 하는 것이다.
    - 합성곱 신경망이 입력이미지의 주요 특성의 정확한 위치에 덜 민감하게 한다. (위치 불변성)
    - 입력 텐서의 높이와 너비를 줄여 전체적인 계산량을 줄여준다. 

3. fully connected layer (완전 연결 계층)
    - flatten 층 
        - 원소의 개수를 유지하면서 다차원 텐서를 1D텐서로 변환한다. 
        - 밀집 층에서 보통 1D텐서를 이용하기 때문이다. 
    - 밀집층 

# 이미지를 다루는 머신러닝 작업에서 합성곱 신경망이 특별히 적합한 이유 

1. 합성곱 신경망은 합성곱 층을 이용해 이미지의 다양한 특성을 추출할 수 있기 때문이다. 
2. 이미지의 위치가 약간 변하거나 해도 출력 값은 동일하게 나오기 때문이다.
3. 동일한 커널을 이용해서 파라미터를 공유해 모델의 일반화 성능을 향상시킨다. 이미지 내의 지역 패턴은 적체 이미지에 반복적으로 나타나기 때문에 더욱 효과적이다. 
4. 공간적인 계층 구조를 가지고 있기 때문이다. 합성곱 신경망은 입력이미지를 여러 계층으로 나누어 처리하는데, 낮은 수준의 계층에서는 픽셀 간의 패턴을 학습하고, 높은 수준의 계층에서는 더 추상적인 개념을 학습한다. 이를 통해 이미지의 여러 특성을 추출할 수 있다.
5. 합성곱 신경망은 고차원 데이터를 처리하는데 적합하기 때문이다. 

# 전이학습의 개념과 일반적인 워크플로 및 전이학습의 장점 

- 전이학습 
    - 어떤 목적을 이루기 위해 만들어진 모델을 다른 작업에 사용 
    - 이전 모델을 새로운 모델에 맞게 fine tuning 해서 사용 

- 일반적인 워크플로 
    - 대규모 데이터셋 - 초기학습 - 베이스 모델 - 전이학습 - 새모델 
        - 초기학습 시에는 많은 데이터와 계산이 필요하다. 
        - 전이학습에는 적은 데이터와 계산만 있으면 된다. 

- 전이학습의 장점 
    - 데이터, 계산량이 줄어든다. 
    - 이전 훈련에서 얻은 특성 추출능력에서 시작한다. 
    - 효율성이 좋다. 
    - 과적합을 방지한다. 
